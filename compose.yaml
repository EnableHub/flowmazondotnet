services:
  flowmazonfrontend:
    container_name: flowmazonfrontend
    build:
      context: ./flowmazonfrontend
      dockerfile: Dockerfile
      args:
        NEXT_PUBLIC_BACKEND_URL: ${NEXT_PUBLIC_BACKEND_URL}
        NEXT_PUBLIC_FARO_URL: ${NEXT_PUBLIC_FARO_URL}
        NEXT_PUBLIC_OTEL_ENVIRONMENT: ${NEXT_PUBLIC_OTEL_ENVIRONMENT}
        NEXT_PUBLIC_FARO_SERVICE_NAME: ${NEXT_PUBLIC_FARO_SERVICE_NAME}

    environment:
      OTEL_EXPORTER_OTLP_ENDPOINT: ${OTEL_EXPORTER_OTLP_ENDPOINT}
      OTEL_EXPORTER_OTLP_PROTOCOL: ${OTEL_EXPORTER_OTLP_PROTOCOL}
      OTEL_EXPORTER_OTLP_HEADERS: ${OTEL_EXPORTER_OTLP_HEADERS}
      # don't need to decalre NEXT_PUBLIC_ vars here again because
      # the Dockerfile would set them (they are passed in as ARGs
      # above) as ENV vars. Of those NEXT_PUBLIC_OTEL_ENVIRONMENT
      # will be read by the server side otel initialization
      # and so would need to be available in the environment,
      # not just at build time (and this is going to be the
      # case).

    restart: always
    ports:
      - 4000:3000
    networks:
      - flowmazon_network

    develop:
      watch:
        - action: rebuild
          path: ./flowmazonfrontend/src

    # Commented out the following
    # dependency as the healthcheck in
    # flowmazonbackend does not work
    # (see comments there)
    #
    # depends_on:
    #   flowmazonbackend:
    #     condition: service_healthy

  # Add more containers below (nginx, postgres, etc.)
  flowmazonbackend:
    container_name: flowmazonbackend
    build:
      context: ./flowmazonbackend
      dockerfile: Dockerfile
    environment:
      ConnectionStrings__FlowmazonDB: ${ConnectionStrings__FlowmazonDB}
      ALLOWED_CORS_ORIGINS: ${ALLOWED_CORS_ORIGINS}
      OTEL_EXPORTER_OTLP_PROTOCOL: ${OTEL_EXPORTER_OTLP_PROTOCOL}
      OTEL_EXPORTER_OTLP_ENDPOINT: ${OTEL_EXPORTER_OTLP_ENDPOINT}
      OTEL_RESOURCE_ATTRIBUTES: ${OTEL_RESOURCE_ATTRIBUTES}
      OTEL_EXPORTER_OTLP_HEADERS: ${OTEL_EXPORTER_OTLP_HEADERS}

    restart: always
    # Even though port 8080 on which Kestrel listens
    # is `EXPOSE`d in the flowmazonapi's Dockerfile
    # (this was part of the ASP.NET Core
    # Dockerfile generated by VS Code, which I extended),
    # The NExt.js app, once served by the Next.js app
    # container (flowmazonfrontend sevice here) runs in
    # a browser on the host machine and access this backend
    # service from there.
    # Hence we need to map port 8080 to a port on the
    # host machine using `ports` key brlow.
    # It also allows us to access it with Postman etc.
    # during local dev testing.
    ports:
      - 5000:8080
    networks:
      - flowmazon_network
    develop:
      watch:
        - action: rebuild
          path: ./flowmazonbackend/flowmazonapi
    depends_on:
      flowmazondb:
        condition: service_healthy
    #
    # This healthcheck doesn't work
    # most probably because the image does
    # not have wget. It also doesnt't seem to
    # have curl.
    # To reinstante the check, create a separate
    # Alpine linux container which can probe
    # the ready endpoint on this container as
    # its own healthcheck, then wait on that
    # container for its healthcheck in
    # flowmazonfrontend service
    #
    # healthcheck:
    #   test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://flowmazonbackend:8080/health/ready"]
    #   interval: 10s
    #   timeout: 5s
    #   retries: 5
  flowmazondb:
    container_name: flowmazondb
    build:
      context: ./flowmazonbackend
      dockerfile: Dockerfile.testdb
      args:
        MIGRATIONS_PATH: ${MIGRATIONS_PATH}
    restart: always
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      # Environment variables for the 10-init-app-user.sql script
      APP_DB_USER: ${APP_DB_USER}
      APP_DB_PASSWORD: ${APP_DB_PASSWORD}
    ports:
      - 6000:5432
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - flowmazon_network
    volumes:
      # Makes the script to create test user in the database
      # with  minimal permissions available to the container
      # in PGSQL initialization scritps directory
      # Being mounted into that special directory,
      # it would run when a container created from the image
      # runs for the first time.
      # It would run after the database named by
      # POSTGRES_DB env var has already been created as the
      # default db (ENTRYPOINT script in the PGSQL image
      # does that) and the script to run migrations on this
      # database has already run (as name of that script
      # starts with 01- and therefore comes before this
      # script in alphabetical ordering which is the order
      # in which the ENTRYPOINT script runs initialization
      # scripts).
      - ./integration-test-support/10-init-app-user.sh:/docker-entrypoint-initdb.d/10-init-app-user.sh
  # aspire_dashboard:
  #   container_name: aspire-dashboard
  #   image: mcr.microsoft.com/dotnet/aspire-dashboard:latest
  #   ports:
  #     - 18888:18888
  #     - 4400:4316
  #   networks:
  #     - flowmazon_network
  # alloy:
  #   image: grafana/alloy:latest
  #   container_name: alloy
  #   ports:
  #     - "12345:12345"
  #     - "12347:12347"
  #   volumes:
  #     # mount config file
  #     - "./.alloy/config.alloy:/etc/alloy/config.alloy"
  #   command:
  #     - run
  #     - --server.http.listen-addr=0.0.0.0:12345
  #     - --storage.path=/var/lib/alloy/data
  #     - /etc/alloy/config.alloy
# Define a network, which allows containers to communicate
# with each other, by using their container name as a hostname
networks:
  flowmazon_network:
    driver: bridge
